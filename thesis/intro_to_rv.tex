%================================================
%====== Chapter 2, Introduction to Runtime Verification
%================================================

\pagestyle{newchap}
\chapter{Introduction to Runtime Verification} \label{chapter-intro-to-rv}

Runtime verification is a new area of research, but the research on other forms
of verification, such as formal methods and testing, goes back several decades.
The terms used in this area are used slightly differently by different
researchers, so we start this chapter in
Section~\ref{section-background-definitions} by giving definitions for some
concepts used in this report, before we delve into some background on formal
methods in Section~\ref{section-formal-methods}. We give an overview of runtime
verification in Section~\ref{section-rv}.

Runtime verification is a technique for verifying a program's compliance
against a specification during runtime. These specifications need to be written
somehow, which we discuss in Section~\ref{section-specifications}. Approaches
for verification are discussed in Section~\ref{section-verification}. For
verification to work, during runtime, the program usually needs to be
instrumented in such a way that the verification process can access all
pertinent data. We discuss this in Section~\ref{section-instrumentation}.


\section{Terms and Definitions}
\label{section-background-definitions}
\label{section-definition-verification}
\label{section-system-model}

\textit{Verification} is the very broad concept of checking that a program does
what it is supposed to, which can be expressed as "Are we building the program
correctly?". This can be contrasted with \textit{validation}, in which we ask:
"Are we building the correct program?" \cite{boehm81engineeringeconomics}.
Validation is concerned with whether the specifications really capture the
requirements we want for the system. Verification is concerned with assuring us
that the program follows its specifications, and it is verification in which
this report takes an interest. Verification includes everything from manually
running the program and parsing through the output, to automated testing
setups, to formal methods.

Both formal methods and testing are thus included in the term verification.

An essential concept in verification is that of a \textit{system model}. A
system model is a construct that represents and describes the behaviour of a
system. It is usually an abstraction of the real system, leaving out the
details that are of no interest to the task at hand, and making other modeling
aspects more prominent.

We use system models constantly in everyday life when we abstract away the
details of how things actually work to a more easy-to-grasp model of how it
seems to work --- e.g., when driving a car, operating a computer, etc. We often
get into trouble when the system model becomes too much simplified, or when it
conflicts with the actual system, because we lose lots of information. A too
detailed system model can give rise to complexity and noise, however, so a
compromise is desirable.

In formal methods, a system model is a mathematical representation of the
system that captures and describes its relevant parts --- the parts of the
system we wish to prove properties about, and reason with formally. In unit
testing, the system model is the unit under test, an isolated slice of the
system, with the rest of the actual system ignored or mocked away.


\section{Formal Methods} \label{section-formal-methods}

Formal methods are verification techniques, based in mathematics, for the
specification and verification of systems. There are several approaches, with
their respective advantages and disadvantages. \textit{Theorem proving} and
\textit{model checking} will be discussed below. They both rely heavily on the
concept of a proof of correctness.

A correctness proof is a certificate, based in mathematics and logics, that a
program/system/function follows its specifications, i.e.\ does what it is
supposed to do.

Research of interest include the early work on formal methods, e.g.\ by Hoare
\cite{hoare69} and Floyd \cite{floyd67}, and work on logics , e.g.\ linear
temporal logic (LTL) by Pnueli \cite{pnueli77}. The seminal work done by Hoare,
Floyd and Pnueli lay the foundation for many interesting approaches for
reasoning about program correctness. LTL is one of the common formal languages
used for specifications in runtime verification.

\textit{Theorem proving}, as started by Hoare \cite{hoare69}, Floyd
\cite{floyd67} and others, is the manual, semi-automated, or (not so often)
fully automated process of mathematically proving that the system follows its
specification. There are many ways of doing such proofs.

One way is to prove that at all points in the program, given inputs satisfying
some pre-conditions, the outputs will satisfy the post-conditions. By
formulating post-conditions for the exit point(s) of the program so that they
follow the specification, and by linking together the pre-conditions of program
points with their preceding program points' post-conditions, we know that
correct input data will yield correct results.

This way of proving correctness often yields very good results --- a complete
and thorough correctness proof for the program. But it is slow, hard to
automate completely, and therefore requires much manual work.  Wading through
large programs thus often becomes impractical.

\textit{Model checking} is the concept of verifying that a \textit{model} of a
system (the \textit{system model}) follows its specification. This requires
that both the model and the specification is written in a mathematical
formalism. Given this, the task becomes to see if the model satisfies the
logical formula of the specification. It is often simpler than theorem proving,
and can be automated.

The model of the system is usually structured as a finite state machine (FSM),
and verification means visiting all accessible states, checking that they
follow the specification (which also can be represented as an FSM). This can be
problematic, especially when the state space becomes very big, something known
as the \textit{state explosion problem}. There are approaches to address this
issue, such as \textit{bounded model checking}, or by using higher-level
abstractions.

Proving that a model of a system is correct can be very useful, but it suffers
from the inherent flaw of only verifying the model, not the actual system. The
model can be difficult to construct, or deviate too far from the system. It can
not take the dynamic properties and configuration of the executing code into
account.

Runtime verification attempts to solve this by dealing directly with the
system, creating its model at runtime.


\section{Runtime Verification} \label{section-rv}

Runtime verification (RV) is a dynamic approach to checking program
correctness, in contrast to testing and the more traditional formal static
analysis techniques discussed in the previous section. Runtime verification
aspires to be a light-weight formal verification technique, see e.g.\
\cite{leucker09abriefaccount,delgado04taxonomy}. It verifies whether properties
of a specification hold \textit{during the execution} of a program.

Runtime verification can be both formal, if the specifications are given a
formal semantics, or informal, if they are more like tests or other program
code.

The specification that should be verified is often written in a formal
language, a logic or a calculus, such as LTL \cite{pnueli77} (this report shows
one exception --- see Chapter~\ref{chapter-approach}). To build a system model
for verifying the properties of the specification, the target program needs to
emit or expose certain events and data. The collected events and data are used
to build the system model. RV frameworks typically use \textit{code
instrumentation} to generate \textit{monitors} for this end.

A monitor is either just part of a recording layer added to the program, which
stores the events and data needed for verification, or also the part of the
machinery that performs verification.

There are two types of verification: \emph{online} and \emph{offline}. In
online verification, the analysis and verification is done during the
execution, in a synchronous manner with the observed system. In offline
verification, a log of events is analysed at a later time. Online verification
allows actions to be taken immediately when violations against the
specifications are detected, but with considerable performance cost. Offline
verification only impacts the performance by collecting data.

When a violation of the specification occurs, simple actions can be taken
(e.g.\ crash the program, log the error, send emails, etc.), or more complex
responses initiated, resulting in a \textit{self-healing} or
\textit{self-adapting} system (see e.g.\ \cite{huebscher08survey}).

Leucker et al.\ present a definition of RV in \cite{leucker09abriefaccount},
together with an exposition of the advantages and disadvantages, similarities
and differences, with other verification approaches. In
\cite{delgado04taxonomy}, Delgado et al.\ classify and review several different
approaches to and frameworks for runtime verification.

The next chapter examines RV in more detail.


\section{Specifications} \label{section-specifications}

A \textit{specification} is essentially something that describes the correct
behaviour of a system. Specifications come in many forms, from the informal
ones like ``I want it have cool buttons'', to the contractual ones written
between companies and their clients, to reference implementations\footnote{For
instance, the only specification for Python is the canonical CPython
implementation. Python is defined as ``what CPython does''.}, to tests (see
e.g.\ Chapter~\ref{chapter-intro-to-unit-testing}), and to \textit{formal
specifications}, written in formal languages, specifying properties that should
verifiably hold for the program. They are is a mathematical constructs that can
be used in verification proofs to show that a program works correctly.

It is these last two types of specifications, tests and formal specifications,
that we are interested in in this report, and which play an important role in
our approach to runtime verification.

In general, specifications should be abstract, written in a high-level
language, and succinctly capture the desired property. Writing erroneous
specifications is of course a possibility; specifications need to be easier for
humans to verify than the program's implementation. There is little point in
having a specification as complex as the program itself, except for as a point
of reference. A program can be seen as an all-encompassing, perfect,
always-true, specification of itself.

For verification in general, specifications can be written and used externally
to the program. They can be used in specialized model-checking tools, in tools
for theorem proving, in test suites, etc.

Runtime verification requires that the specifications are accessible when
building and running the program. The program needs to be instrumented to
expose the correct system model so that the specification can be verified. It
is sometimes desired in runtime verification to do online verification, and
then the specifications need to be available and embedded into the system. A
few different approaches have been tried to support this.

There are several common formalisms for writing specifications, and many papers
that expand, rephrase and illuminate on them. Although they can be quite
different, they share a common origin in the work done by Floyd \cite{floyd67},
Hoare \cite{hoare69}, and others before them. Floyd wrote of formulas as
specifying in/out properties of statements, and chaining these together to form
a formal proof for the program. Hoare elaborated on this idea by basing his
proofs on a few axioms of the programming language and target computer
architecture, and building the proof from there.

Other specification languages take a more informal approach, some allowing
arbitrary code as part of the specification. Below we introduce and give an
overview to the most important and common specification languages.


\subsection{Linear Temporal Logic} \label{section-ltl}

Linear temporal logic (LTL) was first discussed by Pnueli \cite{pnueli77}, and
has since been popular in many areas dealing with a system model containing a
temporal dimension. LTL is simpler than other logics, but expressive enough to
describe many problems of interest for verification. This has been affirmed by
the diverse use of LTL by many researchers \cite{pnueli77}.

LTL uses a system model of \textit{infinite execution traces}, or
\textit{histories}, of the states of the execution. LTL specifications are
formulas that operate on these states. An LTL formula consists of
\textit{propositional variables} that work on the domain model of the state
(checking variables, inputs, global state, etc.), the normal logical operators
such as negation and disjunction, and some temporal operators. The most basic
and common temporal operators are $\boldsymbol{X}$ (\textit{next}), and
$\boldsymbol{U}$ (\textit{until}). Other operators can be derived from these,
such as $\boldsymbol{G}$ (\textit{globally}, or always) and $\boldsymbol{F}$
(\textit{eventually}, or sometime in the future).

An example LTL formula, taken from a list of common specification patterns
\cite{dwyer99patterns}, could be: $S$ precedes $P$, i.e.\ if the state $P$
holds sometime, the state $S$ will hold before it. This is shown in
Figure~\ref{figure-ltl}.

\begin{figure}[h!]
	\[
	\boldsymbol{G} \, P \rightarrow (\neg P \, \boldsymbol{U} \, (S \wedge \neg P))
	\]

	\caption{An example of an LTL formula. This can be read as: Globally, if $P$
	holds, then, before $P$, $S$ held at some point.}
	\label{figure-ltl}
\end{figure}

Bauer et al.\ \cite{bauer06monitoring} introduce a three-valued boolean
semantics for LTL, calling it LTL$_3$, which takes the values (true, false
and~?). This logic is arguably more suited for the finite nature of runtime
verification, whereas LTL was designed with infinite traces in mind. The
semantics of LTL$_3$ reflect the fact that when verifying runtime verification
specifications, the result can not only be that the specification is satisfied
or violated; it can be inconclusive as well. For satisfied or violated
specifications, no further verification is required --- we already know the
outcome. For inconclusive results, we need to continue with the verification,
as, with future events, the result could change into either satisfied or
violated.

There are counterparts to LTL in the real-time setting such Timed Linear
Temporal Logic (TLTL) and Metric Temporal Logic (MTL). They introduces clocks
and time constraints to make specifications of real-time properties possible.
The concept of real-time specifications is of great interest to runtime
verification, but will not be discussed further here as it is out of scope for
this work. See e.g.\ \cite{bauer06monitoring,drusinsky00temporalrover} for
more.

Several runtime verification approaches use LTL or versions thereof as
specification language, see e.g.\ Bauer et al.\
\cite{bauer06monitoring}, Bodden \cite{bodden05efficientrv}, Kähkönen et al.\
\cite{kahkonen09lime}, Java PathExplorer by Havelund et al.\
\cite{havelund04jpax}, Temporal Rover by Drusinsky
\cite{drusinsky00temporalrover}.

\subsection{\textsc{Eagle} and \textsc{RuleR}}

Barringer et al.\ have written \textsc{Eagle} \cite{barringer03eagle} and
\textsc{RuleR} \cite{barringer07ruler} as runtime verification frameworks and
formal logics.  Inefficiency weaknesses were found in \textsc{Eagle}, and
\textsc{RuleR} was proposed as a more efficient alternative, with a more
lower-level logic. They share much of the same basic ideas, however --- they
are written by mostly the same people.

\textsc{Eagle} can be seen as a generalization of other logics, supporting both
past and future tense predicates. It is a temporal finite trace monitoring
rule-based logic, meaning that a specification consists of a set of rules,
which operate on finite sequences of states of the system model, each state
being part of a program execution.

A simple example of an \textsc{Eagle} formula is shown in
Figure~\ref{figure-eagle-always}.
It describes the LTL operator $\boldsymbol{G}$. $\bigcirc$ is the same as the
LTL \textit{next} operator $X$, and \textbf{Form} is the type of $F$, short for
formula. The \textbf{max} qualifier denotes that a maximal solution should be
found for the equation. $\bigcirc \text{Always}(F)$ is thus defined to be true
in the last state of a given trace. A corresponding \textbf{min} qualifier also
exist.

\begin{figure}[h!]
	\[
  \textbf{max} \; \text{Always}(\textbf{Form} \; F) = F \wedge \bigcirc \text{Always}(F)
	\]

  \caption{A simple example of an \textsc{Eagle} formula, semantically
    describing the LTL $\boldsymbol{G}$ operator. Taken from
    \cite{barringer03eagle}.}
	\label{figure-eagle-always}
\end{figure}

The same property can be described in \textsc{RuleR}. If we let $\{r\}$ be the
initial set of rule activations, the formula in
Figure~\ref{figure-ruler-always} say that rule $r$ requires an observation of
$r$ in this state, and that the rule $r$ should hold in the next state.

\begin{figure}[h!]
	\[
    r \; : \; \rightarrow \; a,r
	\]

	\caption{A simple example of a \textsc{RuleR} formula, semantically describing the
  LTL $\boldsymbol{G}$ operator. Taken from \cite{barringer07ruler}.}
	\label{figure-ruler-always}
\end{figure}

An \textsc{Eagle} formula describing the LTL formula from
Figure~\ref{figure-ltl} is shown in Figure~\ref{figure-eagle-ltl}. Note the use
of the \textbf{min} and \textbf{max} quantifiers. Here they mean that
PreviouslySometime$(F)$ should be defined as false on the first state, while
PreviouslyAlways$(F)$ should be true.


\begin{figure}[h!]
  \[
  \begin{array}{rcl}
    \textbf{min} \; \text{PreviouslySometime}(\textbf{Form} \; F) & = & F \vee \odot \, \text{PreviouslySometime}(F) \\
      \textbf{max} \; \text{PreviouslyAlways}(\textbf{Form} \; F) & = & F \wedge \odot \, \text{PreviouslyAlways}(F) \\
  \end{array}
  \]
  \[
    \text{Always}(P \rightarrow (\text{PreviouslySometime}(S) \wedge \text{PreviouslyAlways}(\neg P) \\
  \]

	\caption{A simple example of an \textsc{Eagle} formula, semantically the same as the
  LTL formula from Figure~\ref{figure-ltl}.}
	\label{figure-eagle-ltl}
\end{figure}

Both \textsc{Eagle} and \textsc{RuleR} are strictly more powerful than LTL;
e.g., they both support specifications that allow matching function calls with
function returns, which is in the realm of context-free grammars. LTL does not
support this \cite{barringer03eagle,barringer07ruler}.


\subsection{Design by Contract}

\textit{Design by Contract} is a specification language for runtime
verification without the ability to describe temporal properties. Design by
Contract was introduced by Bertrand Meyer in \cite{meyer92applyingdbc}, and has
been fully implemented in the Eiffel programming
language\footnote{\texttt{http://eiffel.com/}}.

A contract is the idea that functions, and methods on objects, promise to
satisfy certain post-conditions (or promises) if the inputs they are given
satisfy the pre-conditions (or requirements) specified in the contract. Design
by Contract also contains constructs for specifying loop-invariants and
class-invariants, properties that should always hold during loops and for
objects of a class, respectively. Assertions (see below) are also usually
available, to be interspersed with the program code.

\begin{figure}[h!]
	\begin{center}
	\begin{minipage}{0.7\textwidth}
    \lstset{language=Eiffel}
		\lstinputlisting{figures/dbc_example.e}
	\end{minipage}
	\end{center}
  \caption{An example showing the use of the Design-by-Contract concepts of
    pre- and post-conditions, written in Eiffel. Example taken from
    \cite{meyer92applyingdbc}.}
	\label{figure-dbc-example}
\end{figure}

An example of a contract is shown in Figure~\ref{figure-dbc-example}. This
example shows a method \texttt{put-child} for adding nodes to a tree-structure.
Pre-conditions are written in the \texttt{require} block, post-conditions in
the \texttt{ensure} block, and the function body in the \texttt{do} block. The
contract in the example says that if we provide an element, it will be inserted
as a child to the \texttt{Current} node, which will thus have one more child.
Note the use of the language construct \texttt{old} to get the value of an
attribute at before the function executed.

Design by Contract is inspired by Hoare logic, and is essentially Hoare logic
written in a certain style. However, most implementation of Design by Contract,
such as that of Eiffel, and Code
Contracts\footnote{\texttt{http://msdn.microsoft.com/en-us/devlabs/dd491992.aspx}}
in~.Net, allow for arbitrary code in the specifications. The specifications are
thus informal, unless a formalization is given for the programming language
used. The Design by Contract specifications used in Jass (Java with assertions)
have formal semantics \cite{bartetzko01jass}.


\subsection{Assertions}

A common construct that is part of many popular programming languages, like C,
Java and Python, is the \textit{\texttt{assert} statement}. It is a way to
state that some predicate should hold at a point in the program. Usually the
predicate is an expression in the programming language, and is not supposed to
alter the program state.

\begin{figure}[h!]
	\begin{center}
	\begin{minipage}{0.7\textwidth}
    \lstset{language=C}
		\lstinputlisting{figures/cassert_example.c}
	\end{minipage}
	\end{center}
  \caption{An example showing the use of \texttt{assert} in C.}
	\label{figure-c-assert-example}
\end{figure}

An example of the use of assertions in C is shown in
Figure~\ref{figure-c-assert-example}. The example function takes an array of
characters and its size and returns a copy of it. Assertions are used as
pre-conditions to make sure that the inputs are valid --- non-null and
non-negative. Note that the return value of \texttt{malloc} is checked to be
non-null using an if-statement --- this is a case that could happen (if the
system runs out of memory), and should thus be handled by proper error-handling
logic. Assertions are used to check for cases that should never happen.

Assertions are distinct from the normal program flow, and not to be conflated
with exceptions. Assertions check for properties that should always be true,
anything else would be a programming error. Assertions can sometimes be turned
of with a compiler or runtime flag.

Assertions are suitable for simpler specifications, and those more coupled to
code. Assertions are the simplest of runtime verification specifications. If
the languages they are part of are informal, the specifications they represent
are informal as well.



\section{Verification against Specifications} \label{section-verification}

Specifications for runtime verification are written so that programs can be
verified against them --- to see whether they follow the specification, or
violate parts of it.

There are several ways to verify a program against its specification. A common
one used for formal verification, see e.g.\ \cite{bauer06monitoring,
bodden05efficientrv, jalili07rverl, barringer03eagle}, is to generate state
machines from the specification. These state machines, sometimes called
\textit{runtime monitors}, operate with the input language of events emitted by
the program. As the program executes, or a program execution is examined
offline, transitions are taken in the state machines, switching states.
Violations against the specification can be described by failing to find a
valid transition, or ending up in a fail state; Fulfilling a specification can
be described by arriving at an accepting state.

Another approach for verification is to rewrite the instrumented code, adding
assertions that check the properties of the specifications, see e.g.\
\cite{rosenblum95practicalassertions, drusinsky00temporalrover}. This might be
difficult to do with more complex specifications.


\section{Code Instrumentation} \label{section-instrumentation}

For verification to work, the verifier needs access to events happening in the
program. Depending on the system model of the specification language, such
events can be function calls, statement executions, variable assignment, etc.
The program needs to be instrumented for it to emit such events. This often
means wrapping function calls and variable assignments in a ``recording
layer'', which performs the desired action after logging the event. The events
can then be passed on to the verification tools.

In the following sections the main approaches for program instrumentation are
discussed.


\subsection{Pre-processing the Code}

Rosenblum \cite{rosenblum95practicalassertions} and Drusinsky
\cite{drusinsky00temporalrover} use a pre-processor step in the compilation
setup to instrument code, where the specifications (called assertions by
Rosenblum) are transformed from comments into regular code. The verification
code is then compiled together with the program.

An example is shown in Figure~\ref{figure-pre-processing-comments-example}. In
this case, \texttt{assume} work as pre-conditions and \texttt{promise} as
post-conditions, similar to contracts in Design by Contract. \texttt{in x}
means ``the value of \texttt{x} upon entering the function''.

\begin{figure}[h!]
	\begin{center}
	\begin{minipage}{0.7\textwidth}
    \lstset{language=C}
		\lstinputlisting{figures/instrumentation_comments_example.c}
	\end{minipage}
	\end{center}
  \caption{An example showing instrumentation via special comments and code
    pre-processing. Example taken from \cite{rosenblum95practicalassertions}.}
	\label{figure-pre-processing-comments-example}
\end{figure}


\subsection{Post-processing the Code}

It is also possible to rewrite the compiled program, instrumenting the code
after compilation. This way, the program needs no knowledge of the verification
framework. Depending on the compiled objects, this can be more or less
difficult. Binary executables and intermediate formats, such as Java bytecode
or Common Intermediate Language for the Common Language Infrastructure used
by~.Net, require somewhat different approaches.


\subsection{Dynamic Code Rewriting}

In many dynamic languages, such as Python, Ruby or JavaScript, it is possible
to rewrite the code during runtime, which is sometimes called \textit{monkey
patching}. A function to be monitored could be rewritten, adding a lightweight
wrapper that records all calls to it, and then passes on the call to the actual
function. See e.g.\ \cite{matusiak09aoppy} for approaches using dynamic code
rewriting.


\subsection{Aspects} \label{section-aspects}

An interesting approach to code instrumentation is to use aspect-oriented
programming. In aspect-oriented theory, a program should be divided into
modules, each only dealing with their own \textit{concern}. Logging, however,
is a \textit{crosscutting concern}, as it is used by several unrelated modules.
The goal is to not scatter logging code across the modules, and to not tangle
it with the modules' own logic. This can be done by defining the logging code
as \textit{aspects}, which consists of the logging code, called the
\textit{advice}, and a \textit{point cut}, which is a formula describing when
the advice should be executed. The possible execution points for a point cut
are called \textit{join points}.
AspectJ\footnote{\texttt{http://www.eclipse.org/aspectj/}} is the canonical
framework for aspect-oriented programming.

Runtime verification is a typical case of a cross-cutting concern. Bodden
\cite{bodden05efficientrv} and Kähkönen et al.\ \cite{kahkonen09lime} use
AspectJ in their runtime verification implementations. The specifications are
however written adjacent to the code or interfaces being monitored, as Java
Annotations.

Inserting aspects into programs is called \textit{aspect weaving}. It can be
implemented as a pre-processing or post-processing step, or dynamically during
runtime or when code is loaded \cite{kiczales01aspect, matusiak09aoppy}.


\subsection{No instrumentation}

Some runtime verification specifications can be written and executed without
the need for extra instrumentation of the system. Such specifications could
monitor the surrounding environment, e.g.\ check availability of required
services, or make sure that enough disk space is free. Other approaches could be
to use existing features of the system, such as its logging, for runtime
verification. The logs can be parsed by a separate process, during the
execution or as a post-mortem, do determine that the execution followed the
specification. Barringer et al.\ do this in \cite{barringer09tutorial}.

